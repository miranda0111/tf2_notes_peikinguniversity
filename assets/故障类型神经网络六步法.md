# 搭建神经网络的六部法

## 1、import导入相关模块

- 利用这部分代码从自动化库中导入类和函数：
```
import os
import sys
import logging
sys.path.append(r'C:\Users\m1361\.conda\envs\tensorflow\Lib\site-packages')
```
- 用于启动PSCAD的控制器：
```
import mhrc.automation
from mhrc import automation
import mhrc.automation.controller
```

- 此包中的模块允许Python脚本动态使用COM客户端（用于创建可以交互的二进制软件组件）：
`import win32com.client `

- shutil模块提供了支持文件复制和删除的功能：
`import shutil `

- Dispatch函数打开安装在win10上的具有COM接口的程序，可用于轻松操作文件：
```
from win32com.client.gencache import EnsureDispatch as Dispatch
from mhrc.automation.utilities.file import File
from mhrc.automation.utilities.word import Word
import pandas as pd
```
- tensorflow, numpy等搭建卷积神经网络的模块
```
import tensorflow as tf
import numpy as np
from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense
from tensorflow.keras import Model
```

## 2、利用PSCAD自动化来生成数据文件，导入训练集

- 设置文件路径：
```
project_name = '4khz_D_R1_S_Line1'
working_dir =r'C:/mydata/file/pscad_file/4khz_all_20200621_EI/4khz_D_R1_S2/pscad/'
```

- 启动pscad：
```
pscad = mhrc.automation.launch_pscad(pscad_version= 'PSCAD 4.6.2 (x64)', fortran_version= 'GFortran 4.2.1',certificate = False)
path = os.path.join(working_dir, project_name+'.pscx')
pscad.load([path])
```

- 检索pscad里workplace的project，并使用：
```
project = pscad.project(project_name)
project.focus()
```

- 获取Main画布：
`main = project.user_canvas('Main') `

- 设置故障类型、故障距离、故障前攻角、插入角、总的仿真时间：
```
Fault2_list = [1,6,7,10] #故障类型
F_name = ['ag','bcg','abcg','bc'] #对应的输出文件
dist_list= [49,40e3,186e3] #故障距离
per_angel_list = [3,15,37] #故障前攻角
Insert_angel_list =[0.200777,0.203777,0.208611,0.219] #插入角
run_time_list = list(map(lambda x:x+0.02,Insert_angel_list)) #总的仿真时间
Ron_list =[ 0.3,40,177 ] #过渡电阻
```

- 按照PSCAD的参数网格设置对应的元件：
```
Fault2 = main.user_cmp(357725963)  #故障类型
line0 = main.user_cmp(1975369393)  # 
line2 = main.user_cmp(1098280973)  # 故障距离
per_angel = main.user_cmp(484135306)  #故障前功角 
Insert_angel = main.user_cmp(466281308)  #插入角 TF
F_Ron = main.user_cmp(1879528749)  #过渡电阻
```

- 设置元件的参数：
```
for a in range(0,len(Fault2_list)):
    for b in range(0,len(dist_list)):
        for c in range(0,len(per_angel_list)):
            for d in range(0,len(Insert_angel_list)):
                for r in range (0,len (Ron_list)):
                    Fault2.set_parameters(Value = Fault2_list[a])
                    
                    line2.set_parameters( len=dist_list[b])
                    line0.set_parameters( len=200e3-dist_list[b])
                    per_angel.set_parameters( Value = per_angel_list[c])
                    Insert_angel.set_parameters( TF = Insert_angel_list[d] , DF = 0.02)
                    F_Ron.set_parameters( RON =Ron_list[r] )
                    
#输出文件，Line1 + 类型 + 距离0-2 + 故障插入角0-3 + 故障前攻角0-2 + 过度电阻0-2
#输出文件名字：D_R1_S_Line1ab0000_01.out
#一共1080个数据
                    out_name = 'D_R1_S_Line1'+F_name[a]+str(b)+str(d)+str(c) +str(r)
                    project.set_parameters(sample_step=250, PlotType = 1,output_filename= out_name,time_duration = run_time_list[d] )
                    project.save() 
                    project.run()
```
![image.png](https://pic6.58cdn.com.cn/nowater/webim/big/n_v2bc876296af9a4af0b556c8834ad89d60.png)
- 读取D_R1_S_Line1ab0000_01.out等文件，返回一个dataframe，将数据按照模型拼接，生成一个csv文件用于训练模型
```
df1 = pd.read_csv(csvpath+txtname + '_01.out', index_col =0, sep = '\s+', skiprows = [0])  # 读取csv文件 为df
    df2 = pd.read_csv(csvpath+txtname + '_02.out', index_col =0, sep = '\s+', skiprows = [0])   
    df1.columns = ['i2a', 'i2b', 'i2c', 'u2a', 'u2b', 'u2c', 'u3a','u3b','u3c','i3a']   # df 的列对象分为为。。。。
    df2.columns = ['i3b', 'i3c']

dfs = pd.concat([dfx1['u2a']/220, dfx1['i2a'], dfx1['u2b']/220, dfx1['i2b'], dfx1['u2c']/220, dfx1['i2c'],
                      dfx1['u3a']/220, dfx1['i3a'], dfx1['u3b']/220, dfx2['i3b'], dfx1['u3c']/220, dfx2['i3c'],], axis = 0)
```

![image.png](https://pic1.58cdn.com.cn/nowater/webim/big/n_v29ba59f1ba76748f0b231e1ade29c11df.png)

- 将得到的csv文件进行编号得到x_train, y_train
```
def generateds():
    df = pd.read_csv('C:/mydata/file/pscad_file/4khz_all_20200621_EI/4khz_D_R1_S2/4khz_D_R1_S_csv/4khz_D_R1_S_relay34_L1_W1.csv', index_col =0)
    # df = pd.read_csv(csvpath + txtname, index_col =0)
    x, y_ = [], []  # 建立空列表
    for i in range(0, len(df)):
        content = df.iloc[i]  # 循环逐行读取文件中行
        content = np.array(content)
        content = content.reshape(60,20)
        x.append(content)
        value = get_alpha_str4(df.index[i])
        value = value[7:]
        y_.append(value)
        
        print('loading : ' + df.index[i])  # 打印状态提示

    x = np.array(x)  # 变为np.array格式
    y_ = np.array(y_)  # 变为np.array格式
    # y_ = y_.astype(np.float64)  # 变为64位整型
    return x, y_  # 返回输入特征x，返回标签y_
```
![](https://pic2.58cdn.com.cn/nowater/webim/big/n_v249fef28fc4fd405ca627594b4ab04119.png)
![](https://pic7.58cdn.com.cn/nowater/webim/big/n_v2398c61c51a994536849bb7f920a28483.png)   ![](https://pic3.58cdn.com.cn/nowater/webim/big/n_v26d057719d9c044a584e5af23a0bb3400.png)
## 3、卷积网络结构
```
class Baseline(Model):
    def __init__(self):
        super(Baseline, self).__init__()
        self.c1 = Conv2D(filters=20, kernel_size=(5, 5), padding='valid')  # 卷积层
        self.b1 = BatchNormalization()  # BN层
        self.a1 = Activation('relu')  # 激活层
        self.p1 = MaxPool2D(pool_size=(2, 2), strides=2, padding='valid')  # 池化层
        self.d1 = Dropout(0.2)  # dropout层
        self.c2 = Conv2D(filters=20, kernel_size=(3, 3), padding='valid')  # 卷积层
        self.b2 = BatchNormalization()  # BN层
        self.a2 = Activation('relu')  # 激活层
        self.p2 = MaxPool2D(pool_size=(2, 2), strides=2, padding='valid')  # 池化层
        self.d2 = Dropout(0.2)  # dropout层
        

        self.flatten = Flatten()
        self.f1 = Dense(200, activation='relu')
        self.f2 = Dense(21, activation='softmax')

    def call(self, x):
        x = self.c1(x)
        x = self.b1(x)
        x = self.a1(x)
        x = self.p1(x)
        x = self.d1(x)
        x = self.c2(x)
        x = self.b2(x)
        x = self.a2(x)
        x = self.p2(x)
        x = self.d2(x)

        x = self.flatten(x)
        x = self.f1(x)
        y = self.f2(x)
        return y
    
model = Baseline()
```
## 4、配置训练方法 
```
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
              metrics=['sparse_categorical_accuracy'])
```

## 5、执行训练过程
```
history = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_test, y_test), validation_freq=1,
                    callbacks=[cp_callback])
```









